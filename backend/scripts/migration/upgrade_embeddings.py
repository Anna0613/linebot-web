#!/usr/bin/env python3
"""
åµŒå…¥æ¨¡å‹å‡ç´šè…³æœ¬
å°‡ç¾æœ‰çš„çŸ¥è­˜åº«å…§å®¹å¾ all-MiniLM-L6-v2 (384ç¶­) å‡ç´šåˆ° all-mpnet-base-v2 (768ç¶­)
"""
import asyncio
import logging
import sys
from pathlib import Path
from typing import List, Tuple

# æ·»åŠ å°ˆæ¡ˆæ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(str(Path(__file__).parent.parent.parent))

from sqlalchemy import select, update, text
from sqlalchemy.ext.asyncio import AsyncSession

from app.database_async import get_async_session
from app.models.knowledge import KnowledgeChunk
from app.services.embedding_manager import EmbeddingManager

# è¨­å®šæ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class EmbeddingUpgrader:
    """åµŒå…¥æ¨¡å‹å‡ç´šå™¨"""
    
    def __init__(self):
        self.old_model = "all-MiniLM-L6-v2"
        self.new_model = "all-mpnet-base-v2"
        self.batch_size = 50  # æ‰¹æ¬¡è™•ç†å¤§å°
        self.processed_count = 0
        self.total_count = 0
    
    async def get_chunks_to_upgrade(self, db: AsyncSession) -> List[KnowledgeChunk]:
        """ç²å–éœ€è¦å‡ç´šçš„çŸ¥è­˜å¡Š"""
        
        # æŸ¥è©¢æ‰€æœ‰éœ€è¦å‡ç´šçš„çŸ¥è­˜å¡Š
        # æ¢ä»¶ï¼šembedding_new ç‚ºç©ºæˆ– embedding_model ä¸æ˜¯æ–°æ¨¡å‹
        stmt = select(KnowledgeChunk).where(
            (KnowledgeChunk.embedding_new.is_(None)) |
            (KnowledgeChunk.embedding_model != self.new_model)
        ).order_by(KnowledgeChunk.created_at)
        
        result = await db.execute(stmt)
        chunks = result.scalars().all()
        
        logger.info(f"æ‰¾åˆ° {len(chunks)} å€‹éœ€è¦å‡ç´šçš„çŸ¥è­˜å¡Š")
        return chunks
    
    async def upgrade_chunk_embeddings(
        self, 
        db: AsyncSession, 
        chunks: List[KnowledgeChunk]
    ) -> int:
        """æ‰¹æ¬¡å‡ç´šçŸ¥è­˜å¡Šçš„åµŒå…¥å‘é‡"""
        
        if not chunks:
            return 0
        
        # æå–æ–‡æœ¬å…§å®¹
        texts = [chunk.content for chunk in chunks]
        chunk_ids = [chunk.id for chunk in chunks]
        
        try:
            # ä½¿ç”¨æ–°æ¨¡å‹ç”ŸæˆåµŒå…¥å‘é‡
            logger.info(f"æ­£åœ¨ç‚º {len(texts)} å€‹æ–‡æœ¬ç”Ÿæˆæ–°çš„åµŒå…¥å‘é‡...")
            embeddings = await EmbeddingManager.embed_texts_batch(
                texts, 
                model_name=self.new_model,
                batch_size=self.batch_size
            )
            
            # æ‰¹æ¬¡æ›´æ–°è³‡æ–™åº«
            for i, (chunk_id, embedding) in enumerate(zip(chunk_ids, embeddings)):
                await db.execute(
                    update(KnowledgeChunk)
                    .where(KnowledgeChunk.id == chunk_id)
                    .values(
                        embedding_new=embedding,
                        embedding_model=self.new_model,
                        embedding_dimensions="768"
                    )
                )
            
            await db.commit()
            logger.info(f"æˆåŠŸå‡ç´š {len(chunks)} å€‹çŸ¥è­˜å¡Šçš„åµŒå…¥å‘é‡")
            return len(chunks)
            
        except Exception as e:
            logger.error(f"å‡ç´šåµŒå…¥å‘é‡å¤±æ•—: {e}")
            await db.rollback()
            raise
    
    async def run_upgrade(self) -> None:
        """åŸ·è¡Œå®Œæ•´çš„å‡ç´šæµç¨‹"""
        
        logger.info("ğŸš€ é–‹å§‹åµŒå…¥æ¨¡å‹å‡ç´šæµç¨‹")
        logger.info(f"   èˆŠæ¨¡å‹: {self.old_model} (384ç¶­)")
        logger.info(f"   æ–°æ¨¡å‹: {self.new_model} (768ç¶­)")
        
        async for db in get_async_session():
            try:
                # ç²å–éœ€è¦å‡ç´šçš„çŸ¥è­˜å¡Š
                chunks = await self.get_chunks_to_upgrade(db)
                self.total_count = len(chunks)
                
                if self.total_count == 0:
                    logger.info("âœ… æ²’æœ‰éœ€è¦å‡ç´šçš„çŸ¥è­˜å¡Š")
                    return
                
                # åˆ†æ‰¹è™•ç†
                for i in range(0, len(chunks), self.batch_size):
                    batch = chunks[i:i + self.batch_size]
                    batch_num = i // self.batch_size + 1
                    total_batches = (len(chunks) - 1) // self.batch_size + 1
                    
                    logger.info(f"ğŸ“¦ è™•ç†æ‰¹æ¬¡ {batch_num}/{total_batches}")
                    
                    upgraded_count = await self.upgrade_chunk_embeddings(db, batch)
                    self.processed_count += upgraded_count
                    
                    # é¡¯ç¤ºé€²åº¦
                    progress = (self.processed_count / self.total_count) * 100
                    logger.info(f"   é€²åº¦: {self.processed_count}/{self.total_count} ({progress:.1f}%)")
                
                logger.info("âœ… åµŒå…¥æ¨¡å‹å‡ç´šå®Œæˆï¼")
                logger.info(f"   ç¸½å…±è™•ç†: {self.processed_count} å€‹çŸ¥è­˜å¡Š")
                
                # é©—è­‰å‡ç´šçµæœ
                await self.verify_upgrade(db)
                
            except Exception as e:
                logger.error(f"âŒ å‡ç´šéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
                raise
            finally:
                await db.close()
    
    async def verify_upgrade(self, db: AsyncSession) -> None:
        """é©—è­‰å‡ç´šçµæœ"""
        
        logger.info("ğŸ” é©—è­‰å‡ç´šçµæœ...")
        
        # æª¢æŸ¥æ–°æ¨¡å‹çš„çŸ¥è­˜å¡Šæ•¸é‡
        new_model_count = await db.scalar(
            select(KnowledgeChunk.id)
            .where(KnowledgeChunk.embedding_model == self.new_model)
            .count()
        )
        
        # æª¢æŸ¥æœ‰æ–°åµŒå…¥å‘é‡çš„çŸ¥è­˜å¡Šæ•¸é‡
        new_embedding_count = await db.scalar(
            select(KnowledgeChunk.id)
            .where(KnowledgeChunk.embedding_new.isnot(None))
            .count()
        )
        
        logger.info(f"   ä½¿ç”¨æ–°æ¨¡å‹çš„çŸ¥è­˜å¡Š: {new_model_count}")
        logger.info(f"   æœ‰æ–°åµŒå…¥å‘é‡çš„çŸ¥è­˜å¡Š: {new_embedding_count}")
        
        if new_model_count == new_embedding_count == self.total_count:
            logger.info("âœ… é©—è­‰é€šéï¼æ‰€æœ‰çŸ¥è­˜å¡Šéƒ½å·²æˆåŠŸå‡ç´š")
        else:
            logger.warning("âš ï¸  é©—è­‰ç™¼ç¾å•é¡Œï¼Œè«‹æª¢æŸ¥å‡ç´šçµæœ")


async def main():
    """ä¸»å‡½æ•¸"""
    
    print("=" * 60)
    print("ğŸ”„ LINE Bot çŸ¥è­˜åº«åµŒå…¥æ¨¡å‹å‡ç´šå·¥å…·")
    print("=" * 60)
    print()
    
    # ç¢ºèªå‡ç´š
    response = input("ç¢ºå®šè¦å‡ç´šåµŒå…¥æ¨¡å‹å—ï¼Ÿé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“ã€‚(y/N): ")
    if response.lower() not in ['y', 'yes']:
        print("âŒ å‡ç´šå·²å–æ¶ˆ")
        return
    
    try:
        upgrader = EmbeddingUpgrader()
        await upgrader.run_upgrade()
        
        print()
        print("=" * 60)
        print("ğŸ‰ å‡ç´šå®Œæˆï¼")
        print("=" * 60)
        print()
        print("ğŸ“ å¾ŒçºŒæ­¥é©Ÿï¼š")
        print("1. æ¸¬è©¦æ–°çš„åµŒå…¥æ¨¡å‹æ•ˆæœ")
        print("2. å¦‚æœæ•ˆæœæ»¿æ„ï¼Œå¯ä»¥è€ƒæ…®åˆªé™¤èˆŠçš„åµŒå…¥æ¬„ä½")
        print("3. æ›´æ–°æ‡‰ç”¨ç¨‹å¼é…ç½®ä»¥ä½¿ç”¨æ–°æ¨¡å‹")
        
    except Exception as e:
        logger.error(f"âŒ å‡ç´šå¤±æ•—: {e}")
        print()
        print("ğŸ’¡ æ•…éšœæ’é™¤å»ºè­°ï¼š")
        print("1. æª¢æŸ¥è³‡æ–™åº«é€£æ¥")
        print("2. ç¢ºèª sentence-transformers å¥—ä»¶å·²å®‰è£")
        print("3. æª¢æŸ¥ç³»çµ±è¨˜æ†¶é«”æ˜¯å¦è¶³å¤ ")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
